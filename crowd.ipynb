{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11353778,"sourceType":"datasetVersion","datasetId":7104992},{"sourceId":11354079,"sourceType":"datasetVersion","datasetId":7105242}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"LvbbRNZedlkoIP09de8k\")\nproject = rf.workspace(\"noura-voulb\").project(\"crowd-counting-dataset-w3o7w-v4img\")\nversion = project.version(1)\ndataset = version.download(\"yolov8\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:14:25.424907Z","iopub.execute_input":"2025-04-10T11:14:25.425173Z","iopub.status.idle":"2025-04-10T11:14:34.586228Z","shell.execute_reply.started":"2025-04-10T11:14:25.425154Z","shell.execute_reply":"2025-04-10T11:14:34.585435Z"}},"outputs":[{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.60-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2025.1.31)\nCollecting idna==3.7 (from roboflow)\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\nCollecting pillow-heif>=0.18.0 (from roboflow)\n  Downloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.9.0.post0)\nCollecting python-dotenv (from roboflow)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.17.0)\nRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.3.0)\nRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.67.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\nRequirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.55.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->roboflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nDownloading roboflow-1.1.60-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: filetype, python-dotenv, pillow-heif, idna, roboflow\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed filetype-1.2.0 idna-3.7 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.60\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in crowd-counting-dataset-1 to yolov8:: 100%|██████████| 49024/49024 [00:00<00:00, 61378.45it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to crowd-counting-dataset-1 in yolov8:: 100%|██████████| 5808/5808 [00:00<00:00, 7741.08it/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:14:34.587407Z","iopub.execute_input":"2025-04-10T11:14:34.587706Z","iopub.status.idle":"2025-04-10T11:14:39.118538Z","shell.execute_reply.started":"2025-04-10T11:14:34.587683Z","shell.execute_reply":"2025-04-10T11:14:39.117362Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.105-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.105-py3-none-any.whl (994 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.105 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:14:39.120278Z","iopub.execute_input":"2025-04-10T11:14:39.120643Z","iopub.status.idle":"2025-04-10T11:14:43.476052Z","shell.execute_reply.started":"2025-04-10T11:14:39.120611Z","shell.execute_reply":"2025-04-10T11:14:43.475407Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model = YOLO(\"yolov8m.pt\")\n\nmodel.train(\n    data='/kaggle/working/crowd-counting-dataset-1/data.yaml',\n    epochs=50,\n    imgsz=640,\n    batch=4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:52:41.934771Z","iopub.execute_input":"2025-04-10T08:52:41.935203Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 49.7M/49.7M [00:00<00:00, 244MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.105 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/kaggle/working/crowd-counting-dataset-1/data.yaml, epochs=50, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 18.0MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \nModel summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5.35M/5.35M [00:00<00:00, 76.2MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/crowd-counting-dataset-1/train/labels... 2285 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2285/2285 [00:03<00:00, 616.87it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_1248_jpg.rf.637143f0088fd2332d471ad6976f2275.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_1248_jpg.rf.8c5ea0e9aef89fe1a040694f8dcc7ebd.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_407_jpg.rf.3087ed827c32b3fb45fa84c2176e3ec8.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_427_jpg.rf.6be4d9901e26153306714c104e67284d.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_427_jpg.rf.9905d3944242f7d40f69bfe122fd94fe.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_427_jpg.rf.a09c9d34c2b455522cb273c8d2f28c71.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_434_jpg.rf.1b5ccb08c43475dd3625bad49e68223b.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_434_jpg.rf.5b0738af6df27ede81e20629d186a358.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_434_jpg.rf.7124d68b57394f137730cf327b819eec.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_434_jpg.rf.a76a11c2dd059ec116b857ec5c0e07c7.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_436_jpg.rf.0f345f2336cd4cec7a931887bc26dd6d.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_436_jpg.rf.f7c6d6655229aee265409d8cd3a5ea1a.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_469_jpg.rf.3785c35016c5d40b9964561b400a5fcf.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_469_jpg.rf.83975a2cfb49e845bcb60b63b8008c3a.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_472_jpg.rf.75b6048d953fa199c3a5642ad4cb8235.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_472_jpg.rf.8e056f4206abcb36dc13b63482b46510.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_476_jpg.rf.1cbed3cdd44b6619a2d513ecea781da4.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_476_jpg.rf.52dca0f3927f6eb45b49b7c174561859.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_476_jpg.rf.fea290f26afd278f5a6ca7efe1bbea4e.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_529_jpg.rf.151e1d54ccf572226a88b31e43dedbf8.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_529_jpg.rf.eda55e02924730edca43b783d8c3062c.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_529_jpg.rf.ef96fcb4b6f267e85b1bca9d37d4bcf3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/train/images/img_529_jpg.rf.f4c3c85256d70b8b5024dc7f9205ed32.jpg: 1 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/crowd-counting-dataset-1/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/crowd-counting-dataset-1/valid/labels... 382 images, 0 backgrounds, 0 corrupt: 100%|██████████| 382/382 [00:00<00:00, 547.72it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_398_jpg.rf.2599e56d788c39cc44f7fa92be9049b0.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_427_jpg.rf.83447b92f549505e4cf153f000e4fffc.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_469_jpg.rf.bbf15c68146eebd8751b97cfbd0b0a6c.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_472_jpg.rf.55e384d737fcd6823b702a8f09c2e644.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/crowd-counting-dataset-1/valid/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/50      4.52G      2.759      1.636      1.425         70        640: 100%|██████████| 572/572 [01:45<00:00,  5.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [00:12<00:00,  3.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        382      74166      0.511      0.259      0.307      0.107\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/50      7.05G      2.678      1.547      1.357        136        640: 100%|██████████| 572/572 [01:46<00:00,  5.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [00:11<00:00,  4.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        382      74166       0.52      0.287      0.337      0.115\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/50      7.05G        2.6       1.47      1.321        376        640: 100%|██████████| 572/572 [01:45<00:00,  5.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [00:11<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        382      74166       0.54      0.287      0.345      0.121\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/50      7.05G      2.594      1.453      1.318       1967        640: 100%|██████████| 572/572 [01:45<00:00,  5.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [00:11<00:00,  4.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        382      74166      0.568      0.298      0.362      0.133\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/50      7.05G      2.547       1.41      1.292         36        640: 100%|██████████| 572/572 [01:45<00:00,  5.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [00:11<00:00,  4.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        382      74166      0.574      0.322      0.389      0.143\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/50      7.05G      2.504      1.372      1.283         68        640: 100%|██████████| 572/572 [01:45<00:00,  5.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [00:11<00:00,  4.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        382      74166      0.583      0.333      0.395      0.144\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/50      7.05G      2.528      1.363      1.271        463        640:  25%|██▍       | 142/572 [00:26<01:18,  5.49it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"metrics = model.val()\nprint(f\"Recall: {metrics.box.r[0]:.3f}\")\nprint(f\"Percision: {metrics.box.p[0]:.3f}\")\nprint(f\"F1 Score: {metrics.box.f1[0]:.3f}\")\nprint(f\"mAP50: {metrics.box.map50:.3f}\")\nprint(f\"mAP50-95: {metrics.box.map:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:19:04.012671Z","iopub.execute_input":"2025-04-10T11:19:04.012995Z","iopub.status.idle":"2025-04-10T11:19:40.662293Z","shell.execute_reply.started":"2025-04-10T11:19:04.012970Z","shell.execute_reply":"2025-04-10T11:19:40.661563Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.105 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 18.1MB/s]\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/crowd-counting-dataset-1/valid/labels... 382 images, 0 backgrounds, 0 corrupt: 100%|██████████| 382/382 [00:00<00:00, 591.89it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_398_jpg.rf.2599e56d788c39cc44f7fa92be9049b0.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_427_jpg.rf.83447b92f549505e4cf153f000e4fffc.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_469_jpg.rf.bbf15c68146eebd8751b97cfbd0b0a6c.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/crowd-counting-dataset-1/valid/images/img_472_jpg.rf.55e384d737fcd6823b702a8f09c2e644.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/crowd-counting-dataset-1/valid/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:31<00:00,  1.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all        382      74166      0.727      0.408      0.506      0.213\n","output_type":"stream"},{"name":"stderr","text":"invalid value encountered in less\ninvalid value encountered in less\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.9ms preprocess, 22.6ms inference, 0.0ms loss, 21.9ms postprocess per image\nResults saved to \u001b[1mruns/detect/val\u001b[0m\nRecall: 0.408\nPercision: 0.727\nF1 Score: 0.523\nmAP50: 0.506\nmAP50-95: 0.213\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# بعد التدريب، استخراج المقاييس من النتائج\nresults = model.val()\n\n# استخراج المقاييس من النتائج\nrecall = results.box.r[0]   # الاسترجاع\nprecision = results.box.p[0]  # الدقة\nf1_score = results.box.f1[0]  # F1 Score\nmap50 = results.box.map50  # mAP50\nmap50_95 = results.box.map  # mAP50-95\n\n# طباعة القيم\nprint(f\"Recall: {recall:.3f}\")\nprint(f\"Precision: {precision:.3f}\")\nprint(f\"F1 Score: {f1_score:.3f}\")\nprint(f\"mAP50: {map50:.3f}\")\nprint(f\"mAP50-95: {map50_95:.3f}\")\n\n# رسم الرسومات البيانية\nmetrics_values = {\n    'Recall': recall,\n    'Precision': precision,\n    'F1 Score': f1_score,\n    'mAP50': map50,\n    'mAP50-95': map50_95\n}\n\n# رسم دقة الموديل\nfig, ax = plt.subplots(figsize=(10, 6))\nax.bar(metrics_values.keys(), metrics_values.values(), color='skyblue')\nax.set_title('Model Evaluation Metrics')\nax.set_xlabel('Metric')\nax.set_ylabel('Score')\nax.set_ylim(0, 1)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:48:43.644411Z","iopub.execute_input":"2025-04-10T11:48:43.644803Z","iopub.status.idle":"2025-04-10T11:48:43.672677Z","shell.execute_reply.started":"2025-04-10T11:48:43.644776Z","shell.execute_reply":"2025-04-10T11:48:43.671368Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-31bcfe61d4e4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# بعد التدريب، استخراج المقاييس من النتائج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# استخراج المقاييس من النتائج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# الاسترجاع\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'val'"],"ename":"AttributeError","evalue":"'Sequential' object has no attribute 'val'","output_type":"error"}],"execution_count":62},{"cell_type":"code","source":"import os\ntest_images_path = '/kaggle/working/crowd-counting-dataset-1/test/images'\nfor image_name in os.listdir(test_images_path):\n    image_path = os.path.join(test_images_path, image_name)\n    model.predict(image_path, save=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:27:06.774615Z","iopub.execute_input":"2025-04-10T11:27:06.774916Z","iopub.status.idle":"2025-04-10T11:27:15.668187Z","shell.execute_reply.started":"2025-04-10T11:27:06.774895Z","shell.execute_reply":"2025-04-10T11:27:15.667526Z"}},"outputs":[{"name":"stdout","text":"\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1156_jpg.rf.827b6804662eceeb86e9cefd5fcfe358.jpg: 640x640 184 peoples, 37.9ms\nSpeed: 2.9ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_366_jpg.rf.11718f69361b16c470924dbf7a695d01.jpg: 640x640 65 peoples, 36.9ms\nSpeed: 1.9ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1165_jpg.rf.c8c89100527b5a7d2f093c9be47eb3fe.jpg: 640x640 97 peoples, 37.0ms\nSpeed: 1.8ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1050_jpg.rf.ffb92562326ed3e8880bfe97ef4f53d0.jpg: 640x640 145 peoples, 36.9ms\nSpeed: 1.9ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1106_jpg.rf.1ad4189736bc5541d9b9d3499f1b01b4.jpg: 640x640 102 peoples, 36.9ms\nSpeed: 2.0ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_515_jpg.rf.6c39b5e2ae8dc54f0921f58300b59d6b.jpg: 640x640 24 peoples, 24.5ms\nSpeed: 1.9ms preprocess, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_695_jpg.rf.a111b6653a7b8cf3399423633b7e8e4d.jpg: 640x640 73 peoples, 24.5ms\nSpeed: 1.8ms preprocess, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_810_jpg.rf.dc97ffa4ada23a4138f9988057cbb44b.jpg: 640x640 70 peoples, 24.3ms\nSpeed: 1.8ms preprocess, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_577_jpg.rf.6b4e77e7353be416095de1aed596bf57.jpg: 640x640 19 peoples, 24.1ms\nSpeed: 1.8ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_715_jpg.rf.1e0294b4c94a33f480e394e1019f5c87.jpg: 640x640 43 peoples, 24.0ms\nSpeed: 1.8ms preprocess, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_116_jpg.rf.bdbd0c66b10bdc8679d3829edb1c06be.jpg: 640x640 114 peoples, 20.7ms\nSpeed: 1.9ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1088_jpg.rf.ea0372933639b9e16663d5e870b110ff.jpg: 640x640 76 peoples, 18.4ms\nSpeed: 1.8ms preprocess, 18.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_451_jpg.rf.a7bdd8f93d4415f448d8ee35c7085a83.jpg: 640x640 28 peoples, 17.6ms\nSpeed: 2.4ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_405_jpg.rf.f7c611be85863b832861fe69764d7c10.jpg: 640x640 279 peoples, 20.0ms\nSpeed: 1.8ms preprocess, 20.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_485_jpg.rf.90a7c75ed98eb3c6815983539ced9878.jpg: 640x640 51 peoples, 17.5ms\nSpeed: 1.8ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_498_jpg.rf.f8d8a80e45dbf581c5cc37df408c975e.jpg: 640x640 20 peoples, 17.2ms\nSpeed: 1.8ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1132_jpg.rf.3ae85973ee4f141062419d69a579f8aa.jpg: 640x640 61 peoples, 20.3ms\nSpeed: 1.9ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_790_jpg.rf.ac9c73a36db216930177b849d6348811.jpg: 640x640 98 peoples, 19.7ms\nSpeed: 1.8ms preprocess, 19.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1084_jpg.rf.8daa8b095fe107b5977ee979d8403506.jpg: 640x640 29 peoples, 18.3ms\nSpeed: 1.9ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_812_jpg.rf.6d48cefbb2d290b6163a98b9bbb38c39.jpg: 640x640 136 peoples, 18.1ms\nSpeed: 1.8ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1067_jpg.rf.b81d925db59e8063f221484abdcb25e7.jpg: 640x640 138 peoples, 18.4ms\nSpeed: 1.9ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1086_jpg.rf.6d831e784d95f9165488f1c14b2a22f4.jpg: 640x640 28 peoples, 18.5ms\nSpeed: 1.8ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_134_jpg.rf.04e6cbe23dd1cd53170c83ac7a3fa85c.jpg: 640x640 19 peoples, 20.1ms\nSpeed: 1.8ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1118_jpg.rf.b7da889069702ca5e8507b6c9d2b95c4.jpg: 640x640 63 peoples, 19.3ms\nSpeed: 1.8ms preprocess, 19.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_296_jpg.rf.0e34c9a2af97a479cdd72ffb308efbf2.jpg: 640x640 29 peoples, 19.9ms\nSpeed: 1.8ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_777_jpg.rf.88ca86e17db5831dd8a0d9444150d2c7.jpg: 640x640 170 peoples, 20.3ms\nSpeed: 1.9ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_740_jpg.rf.ac4f16ea8a9ec9e315259b59c5313733.jpg: 640x640 130 peoples, 17.9ms\nSpeed: 1.9ms preprocess, 17.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1243_jpg.rf.0fae31602fbc837567d622f5d4df0fc6.jpg: 640x640 13 peoples, 17.8ms\nSpeed: 1.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_103_jpg.rf.dca63a9fa1b667cfa0bc77c4d1e0e522.jpg: 640x640 39 peoples, 19.2ms\nSpeed: 2.1ms preprocess, 19.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1144_jpg.rf.0c99a154d9de8ee03a9822f61da29b50.jpg: 640x640 34 peoples, 19.2ms\nSpeed: 1.9ms preprocess, 19.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_696_jpg.rf.b09a50d6cc204fe1cb7b623cb8a777cd.jpg: 640x640 17 peoples, 20.7ms\nSpeed: 1.8ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1093_jpg.rf.108dc67d9769b8e2306bde317cd6961d.jpg: 640x640 107 peoples, 19.1ms\nSpeed: 1.8ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1027_jpg.rf.0ede423a7df33f34e9cf76cf365946c1.jpg: 640x640 15 peoples, 19.3ms\nSpeed: 1.8ms preprocess, 19.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_743_jpg.rf.fc8be3a8c1f08778f16b15415d7bfc24.jpg: 640x640 71 peoples, 20.9ms\nSpeed: 1.8ms preprocess, 20.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1270_jpg.rf.d5b5ccbd9fc591b72fd9aaf913dd80aa.jpg: 640x640 99 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_348_jpg.rf.f387b92302734377431d38b2ea2c64a5.jpg: 640x640 28 peoples, 18.1ms\nSpeed: 1.8ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1086_jpg.rf.7fb0f7a3cfba62eccf1d6237ada1645a.jpg: 640x640 28 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1057_jpg.rf.7cae6cc05e2befbdce9575a5128d7d99.jpg: 640x640 158 peoples, 19.8ms\nSpeed: 1.9ms preprocess, 19.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_177_jpg.rf.02b5942661d7631e59594d4646f00c91.jpg: 640x640 112 peoples, 18.3ms\nSpeed: 1.9ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1085_jpg.rf.c7e5f58b0aa810a91e993609d5308e05.jpg: 640x640 101 peoples, 17.5ms\nSpeed: 2.7ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_683_jpg.rf.cba268613c2fac68ac0f18a0d2d8a157.jpg: 640x640 85 peoples, 17.8ms\nSpeed: 2.0ms preprocess, 17.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_675_jpg.rf.227b9c9ab2fbbe278e13c8abae1a9c86.jpg: 640x640 11 peoples, 18.0ms\nSpeed: 2.0ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_838_jpg.rf.097fc1207a2f21eb6157d81f341402d1.jpg: 640x640 29 peoples, 18.0ms\nSpeed: 1.9ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1213_jpg.rf.ec9a972b44a25e8b601504f66d06be51.jpg: 640x640 42 peoples, 21.9ms\nSpeed: 2.0ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_47_jpg.rf.8320818cae566df3e9d49ce8b6c17886.jpg: 640x640 38 peoples, 21.9ms\nSpeed: 1.9ms preprocess, 21.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_253_jpg.rf.92c30ce7fbd0942cab82b674204215bb.jpg: 640x640 42 peoples, 21.8ms\nSpeed: 2.1ms preprocess, 21.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1047_jpg.rf.b245ab179b75156d01cad795a2b67f89.jpg: 640x640 101 peoples, 19.2ms\nSpeed: 1.9ms preprocess, 19.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_32_jpg.rf.7a84ba28316f0253c4f81f76c6eef634.jpg: 640x640 38 peoples, 18.8ms\nSpeed: 1.9ms preprocess, 18.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_59_jpg.rf.654c294bc1de3bdbf753d01780b59042.jpg: 640x640 146 peoples, 19.6ms\nSpeed: 1.9ms preprocess, 19.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_294_jpg.rf.3f932adb4bab57992b10c51c52181e6c.jpg: 640x640 172 peoples, 18.2ms\nSpeed: 2.0ms preprocess, 18.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_445_jpg.rf.efac693d5831d6d0f9fb3451bf7613b5.jpg: 640x640 59 peoples, 17.3ms\nSpeed: 1.9ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_743_jpg.rf.77cb7c3506549309b7df0d8a43a3704c.jpg: 640x640 71 peoples, 19.8ms\nSpeed: 1.8ms preprocess, 19.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1053_jpg.rf.c868f96b1589287217b9106097895547.jpg: 640x640 84 peoples, 19.2ms\nSpeed: 1.8ms preprocess, 19.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_202_jpg.rf.6498186995f5127614b736057e744b16.jpg: 640x640 27 peoples, 18.3ms\nSpeed: 1.8ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_28_jpg.rf.174a3f5bda778e851cc771d361d009c9.jpg: 640x640 168 peoples, 20.0ms\nSpeed: 2.0ms preprocess, 20.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_604_jpg.rf.05b76b2b53a6a00e6c949f935d3ab6df.jpg: 640x640 34 peoples, 17.9ms\nSpeed: 2.0ms preprocess, 17.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1113_jpg.rf.5f8df8306efec0ef17c13b90b42a0769.jpg: 640x640 78 peoples, 18.5ms\nSpeed: 2.0ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_55_jpg.rf.f8262fc5b9acffaf2c4a46690c9904e4.jpg: 640x640 30 peoples, 19.2ms\nSpeed: 2.0ms preprocess, 19.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1087_jpg.rf.dc7b100bd0687be5fb764627a835d7e0.jpg: 640x640 57 peoples, 18.7ms\nSpeed: 1.9ms preprocess, 18.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_472_jpg.rf.e4f8d17a051ed832ab50c3e8451b2031.jpg: 640x640 40 peoples, 18.9ms\nSpeed: 2.1ms preprocess, 18.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_488_jpg.rf.dfc8d0daa3c6bf4aa4f2f2dd6a150253.jpg: 640x640 75 peoples, 20.7ms\nSpeed: 2.0ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1036_jpg.rf.215f126630d80fe5b6b0ae0b6f55560e.jpg: 640x640 32 peoples, 19.2ms\nSpeed: 2.0ms preprocess, 19.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_544_jpg.rf.2739af3e5d17b7362c0198339839c24c.jpg: 640x640 300 peoples, 18.2ms\nSpeed: 1.8ms preprocess, 18.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1109_jpg.rf.1327092d941f39dd81b514cfaa197a1e.jpg: 640x640 56 peoples, 17.7ms\nSpeed: 1.8ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1215_jpg.rf.1eab7d6f48995c62c93ed2d36ed86292.jpg: 640x640 125 peoples, 18.7ms\nSpeed: 1.8ms preprocess, 18.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_387_jpg.rf.32ddef6e089abf69f8b6ce4133e98f6b.jpg: 640x640 26 peoples, 18.3ms\nSpeed: 1.9ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1039_jpg.rf.ac765464b0d38ba5bd5a45f67f80a1b3.jpg: 640x640 44 peoples, 20.9ms\nSpeed: 2.2ms preprocess, 20.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_722_jpg.rf.75fff59b699c38c7f49991e17fcdc6c2.jpg: 640x640 60 peoples, 19.5ms\nSpeed: 1.9ms preprocess, 19.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_625_jpg.rf.c93bb90c7e415aae57f66f86044c99f6.jpg: 640x640 40 peoples, 18.8ms\nSpeed: 1.9ms preprocess, 18.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_740_jpg.rf.b8466e6a0aeef3973f0ec95e3e0291b4.jpg: 640x640 25 peoples, 20.7ms\nSpeed: 1.9ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1019_jpg.rf.3b463cedbc593b20f89f808a0883b5c7.jpg: 640x640 35 peoples, 19.4ms\nSpeed: 1.9ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_692_jpg.rf.9ca9ca74dd8516a0540a1f5a5743a0ca.jpg: 640x640 49 peoples, 19.8ms\nSpeed: 1.9ms preprocess, 19.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_353_jpg.rf.598b61f7fbd8e3af5eafbb31cbef596c.jpg: 640x640 193 peoples, 20.4ms\nSpeed: 1.8ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_215_jpg.rf.ac4fd62bd875f2338752272a72112d41.jpg: 640x640 62 peoples, 17.8ms\nSpeed: 1.9ms preprocess, 17.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1060_jpg.rf.405203c23a4ae3aff691e327eb8d6ef9.jpg: 640x640 226 peoples, 19.5ms\nSpeed: 1.9ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_800_jpg.rf.3637874c314b8b54272f4ba85c0bd0db.jpg: 640x640 41 peoples, 17.9ms\nSpeed: 1.8ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_66_jpg.rf.5749c00f51f2fd559e16fca66bc7522b.jpg: 640x640 32 peoples, 17.6ms\nSpeed: 1.8ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_792_jpg.rf.fb29661f8ec51ad34e30e8cf3c0deff1.jpg: 640x640 64 peoples, 21.0ms\nSpeed: 1.8ms preprocess, 21.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_580_jpg.rf.4e185c6e817df6eef5f02b23d0a39953.jpg: 640x640 19 peoples, 19.7ms\nSpeed: 1.8ms preprocess, 19.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_196_jpg.rf.327d835040d698f2b114f4b3cefc6d0a.jpg: 640x640 30 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_717_jpg.rf.519572340691b98f40177d1a2ca7e4ba.jpg: 640x640 53 peoples, 19.9ms\nSpeed: 1.9ms preprocess, 19.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_324_jpg.rf.444c73197f320fb6558ebaff56d91802.jpg: 640x640 161 peoples, 19.2ms\nSpeed: 1.8ms preprocess, 19.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_498_jpg.rf.2da23617d755c2883a6b3b787d631ed1.jpg: 640x640 19 peoples, 18.8ms\nSpeed: 1.8ms preprocess, 18.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_802_jpg.rf.0778ca4dbc8eebc0adf94d3415b0ad69.jpg: 640x640 53 peoples, 19.7ms\nSpeed: 1.7ms preprocess, 19.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_841_jpg.rf.67df5b23f87d289ce5e7e9d263e89266.jpg: 640x640 290 peoples, 19.3ms\nSpeed: 1.9ms preprocess, 19.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_312_jpg.rf.bcccbf739945b5b11cde3a65ed9d0f75.jpg: 640x640 168 peoples, 17.3ms\nSpeed: 1.9ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_767_jpg.rf.4289788a4cb07021d37b57af5572bfda.jpg: 640x640 59 peoples, 17.2ms\nSpeed: 1.9ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_78_jpg.rf.f6a6bc6aac21c7714a72f2506a58163a.jpg: 640x640 38 peoples, 18.9ms\nSpeed: 1.9ms preprocess, 18.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_33_jpg.rf.1281f9e525718a0b55befccc0bf691bb.jpg: 640x640 38 peoples, 18.5ms\nSpeed: 1.9ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_33_jpg.rf.ce2eb21c2286e28749eff28d848bc0eb.jpg: 640x640 38 peoples, 21.5ms\nSpeed: 2.1ms preprocess, 21.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_72_jpg.rf.028952258a7e54a52c3e82250755a89b.jpg: 640x640 21 peoples, 20.1ms\nSpeed: 1.9ms preprocess, 20.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_634_jpg.rf.b138ce1ba6980ff8931c8912100c7618.jpg: 640x640 30 peoples, 19.9ms\nSpeed: 1.8ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_335_jpg.rf.d98dc666909840359f0369f35a82558f.jpg: 640x640 70 peoples, 20.4ms\nSpeed: 1.9ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_295_jpg.rf.5695217c7824b0698efce3b05487baec.jpg: 640x640 46 peoples, 19.1ms\nSpeed: 1.9ms preprocess, 19.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_279_jpg.rf.e144be0f1768e4a0082c7de9b98e2e0d.jpg: 640x640 115 peoples, 19.7ms\nSpeed: 1.9ms preprocess, 19.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_756_jpg.rf.97c51831354e02cf9dc78b243ea0c8fa.jpg: 640x640 36 peoples, 18.8ms\nSpeed: 1.9ms preprocess, 18.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_790_jpg.rf.15269b9880f52ba933461d24a3f8d326.jpg: 640x640 98 peoples, 20.7ms\nSpeed: 1.9ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_743_jpg.rf.50dee9d4ea6f039de364e92c68f3f854.jpg: 640x640 71 peoples, 19.1ms\nSpeed: 1.8ms preprocess, 19.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_674_jpg.rf.b9ca2e644ad7966414feb9b45214502c.jpg: 640x640 83 peoples, 18.4ms\nSpeed: 1.8ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1179_jpg.rf.9de7ba45084c2d5578ac185019abc3e0.jpg: 640x640 29 peoples, 18.3ms\nSpeed: 2.0ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_853_jpg.rf.a7acba192e53f0317645086762906b42.jpg: 640x640 203 peoples, 20.2ms\nSpeed: 1.9ms preprocess, 20.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1041_jpg.rf.247b1e34926377d663315cb17d0278af.jpg: 640x640 98 peoples, 18.0ms\nSpeed: 1.9ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_407_jpg.rf.e333fa7d58e6bd10065ef0a62c810f20.jpg: 640x640 63 peoples, 18.3ms\nSpeed: 1.9ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_218_jpg.rf.9907087000a8c2e248a3177753485b90.jpg: 640x640 49 peoples, 19.6ms\nSpeed: 2.0ms preprocess, 19.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_448_jpg.rf.fd5c6419dbae4daaa673fa51f3053af8.jpg: 640x640 18 peoples, 20.7ms\nSpeed: 1.9ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1002_jpg.rf.cd1157993d2488bbdd2d771823fc5c60.jpg: 640x640 86 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_665_jpg.rf.137fcd926e722bd09c59060cd624867b.jpg: 640x640 99 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_675_jpg.rf.1e30867db70a5cc3b0e7c5afd8d01ff2.jpg: 640x640 11 peoples, 18.9ms\nSpeed: 1.9ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1230_jpg.rf.0ff1891af3fb863b0f0614d0646591e2.jpg: 640x640 45 peoples, 21.3ms\nSpeed: 1.9ms preprocess, 21.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_376_jpg.rf.8fb82d60a0584b5b4a21a2e4c064e91e.jpg: 640x640 60 peoples, 19.5ms\nSpeed: 1.9ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_525_jpg.rf.5bd5d6dc05a7cde2cca311b19d9e04bb.jpg: 640x640 29 peoples, 19.0ms\nSpeed: 1.9ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_828_jpg.rf.bc528ebe6c934c9f6c9560892cb9f0b3.jpg: 640x640 47 peoples, 21.0ms\nSpeed: 2.0ms preprocess, 21.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_469_jpg.rf.eb1d7c7ccb71f5c5ddf740d8a9647705.jpg: 640x640 4 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1242_jpg.rf.46711cd03e735587928f714c8e84eb44.jpg: 640x640 66 peoples, 21.0ms\nSpeed: 1.8ms preprocess, 21.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_733_jpg.rf.a76028e35dc9af9d77c7ee15451033a5.jpg: 640x640 101 peoples, 19.8ms\nSpeed: 2.0ms preprocess, 19.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_329_jpg.rf.4e2996cb8919e3405bb929561ea54c92.jpg: 640x640 36 peoples, 18.7ms\nSpeed: 1.8ms preprocess, 18.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_168_jpg.rf.56ef5ce042ff58b982e8a312afde47c3.jpg: 640x640 142 peoples, 18.5ms\nSpeed: 1.8ms preprocess, 18.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_126_jpg.rf.0537357be2eeed7b515466c584d3c598.jpg: 640x640 69 peoples, 18.3ms\nSpeed: 1.8ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_726_jpg.rf.31b94a2532a2b8965b7ded5c1c52aee5.jpg: 640x640 20 peoples, 19.9ms\nSpeed: 1.9ms preprocess, 19.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_767_jpg.rf.c77a12ef132dbc437f57da98b04dad0d.jpg: 640x640 57 peoples, 20.1ms\nSpeed: 1.9ms preprocess, 20.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_242_jpg.rf.c9e43a7e639db25d20cebb1fa1744bc9.jpg: 640x640 27 peoples, 19.2ms\nSpeed: 1.8ms preprocess, 19.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_577_jpg.rf.249304833a62936dc4c8a60e0a2ff46f.jpg: 640x640 19 peoples, 19.1ms\nSpeed: 1.8ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_392_jpg.rf.c4f4c69a40aee6ba8ad075ef8bd059b5.jpg: 640x640 106 peoples, 19.1ms\nSpeed: 1.8ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1201_jpg.rf.2872ac4df7168bfa805b9f148645a092.jpg: 640x640 182 peoples, 19.0ms\nSpeed: 2.3ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1031_jpg.rf.18ea43bb82bafef8363e8dd1239b15ca.jpg: 640x640 247 peoples, 18.5ms\nSpeed: 1.9ms preprocess, 18.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_175_jpg.rf.49b8de22cfd96e53a6b3d1ed2bddae3f.jpg: 640x640 199 peoples, 17.3ms\nSpeed: 1.9ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_775_jpg.rf.25e86705ff3d69f307bce356203e34f2.jpg: 640x640 202 peoples, 17.8ms\nSpeed: 1.9ms preprocess, 17.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_505_jpg.rf.304b28e9f75487146a83bf391fcf6fb7.jpg: 640x640 58 peoples, 17.2ms\nSpeed: 1.8ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_274_jpg.rf.f73d735c56e014aaf185df942f64bae8.jpg: 640x640 150 peoples, 19.8ms\nSpeed: 1.8ms preprocess, 19.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_220_jpg.rf.e388a5ac64d543ac549c2ae92e643b7b.jpg: 640x640 75 peoples, 18.3ms\nSpeed: 1.8ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_151_JPG_jpg.rf.2338b4a80b48bc52762c5098aa3dbf19.jpg: 640x640 54 peoples, 20.0ms\nSpeed: 1.9ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_820_jpg.rf.2353191831d876ff5db7a2f0df87790e.jpg: 640x640 116 peoples, 19.6ms\nSpeed: 2.0ms preprocess, 19.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1179_jpg.rf.8ab89702f49cccb67f4e1c6750766492.jpg: 640x640 32 peoples, 18.3ms\nSpeed: 2.1ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_267_jpg.rf.30224802723ab134920d01903078e9a1.jpg: 640x640 105 peoples, 18.0ms\nSpeed: 1.8ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_807_jpg.rf.1ff214191066f205040f82648f3c8ef1.jpg: 640x640 98 peoples, 18.8ms\nSpeed: 1.9ms preprocess, 18.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_525_jpg.rf.50f8218e9e5700e246fbc04987d2f5e5.jpg: 640x640 20 peoples, 19.0ms\nSpeed: 1.8ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_836_jpg.rf.45053d3cef653a02fddd6450c94db392.jpg: 640x640 300 peoples, 21.2ms\nSpeed: 1.8ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_158_jpg.rf.839d540e5513e392e9bd8b2eaca00836.jpg: 640x640 235 peoples, 17.4ms\nSpeed: 1.9ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_316_jpg.rf.25b2e2332e2a611362361c5dcfc748e1.jpg: 640x640 37 peoples, 17.4ms\nSpeed: 1.9ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_634_jpg.rf.cae469622929f683c680579c76ca74d4.jpg: 640x640 30 peoples, 18.2ms\nSpeed: 1.8ms preprocess, 18.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1190_jpg.rf.a85e5034faa084214c609c8afbc31f62.jpg: 640x640 115 peoples, 20.5ms\nSpeed: 1.8ms preprocess, 20.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_442_jpg.rf.2b974054ff0b7c57bfc15c66344a758d.jpg: 640x640 24 peoples, 19.4ms\nSpeed: 1.7ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_846_jpg.rf.8cb053e5dfa0cc8fb274fa2a24b5e1f7.jpg: 640x640 19 peoples, 18.4ms\nSpeed: 1.8ms preprocess, 18.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_292_jpg.rf.7c5c386e5f422d485ab86b8f62f53b6d.jpg: 640x640 36 peoples, 21.8ms\nSpeed: 1.8ms preprocess, 21.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_270_jpg.rf.ebc10951d70b1250af119e782ec927bd.jpg: 640x640 22 peoples, 19.7ms\nSpeed: 1.9ms preprocess, 19.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_245_jpg.rf.a85ab70a7b3a072db01e6fcd9e7c96e7.jpg: 640x640 39 peoples, 20.6ms\nSpeed: 2.0ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1217_jpg.rf.9e61f6c0ffbd2811e72682816eff1521.jpg: 640x640 103 peoples, 20.0ms\nSpeed: 1.9ms preprocess, 20.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_671_jpg.rf.9af989550586f0acad930e82d341a173.jpg: 640x640 43 peoples, 18.6ms\nSpeed: 2.0ms preprocess, 18.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_615_jpg.rf.37d59f88c947aed42a69dc39ec8f5e44.jpg: 640x640 28 peoples, 18.0ms\nSpeed: 1.8ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_72_jpg.rf.4591ae9e9d3e43ea0e94ad82af20a821.jpg: 640x640 21 peoples, 21.1ms\nSpeed: 1.8ms preprocess, 21.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_690_jpg.rf.73b7f70b941ca6b2c102e457c2247195.jpg: 640x640 48 peoples, 20.0ms\nSpeed: 1.8ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_38_jpg.rf.39f45f17e38ad174d1aabbb4d00d7891.jpg: 640x640 71 peoples, 19.9ms\nSpeed: 1.9ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_455_jpg.rf.e757885131be4d1d9ce968dc1eec70e2.jpg: 640x640 40 peoples, 20.3ms\nSpeed: 1.8ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_483_jpg.rf.bf364d23d8bde1f48a90abe57cc962cd.jpg: 640x640 61 peoples, 19.5ms\nSpeed: 1.8ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_476_jpg.rf.3be67837bfe75c3a596fbbccb043ad44.jpg: 640x640 (no detections), 18.3ms\nSpeed: 2.0ms preprocess, 18.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1173_jpg.rf.abc36a8bba4b2b1c9af1fbcc82c7b6d0.jpg: 640x640 42 peoples, 21.6ms\nSpeed: 1.9ms preprocess, 21.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_528_jpg.rf.989d5aedf2ee197792b69aef9301affb.jpg: 640x640 16 peoples, 20.0ms\nSpeed: 1.9ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1095_jpg.rf.c399180e931311bafb4b32129c0bd5e7.jpg: 640x640 177 peoples, 21.2ms\nSpeed: 2.0ms preprocess, 21.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_832_jpg.rf.f4a99a6f0a4b02e49c072eb53b95fe5e.jpg: 640x640 49 peoples, 18.4ms\nSpeed: 1.8ms preprocess, 18.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_798_jpg.rf.f5fb9871f28b567f83a758914b2ffc04.jpg: 640x640 63 peoples, 19.4ms\nSpeed: 1.9ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1215_jpg.rf.0dd31a37afcc5b2bc21df57031ae0a55.jpg: 640x640 125 peoples, 19.6ms\nSpeed: 1.8ms preprocess, 19.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_230_jpg.rf.00a8583c44b2e0ebfc80139b8240d75a.jpg: 640x640 14 peoples, 18.3ms\nSpeed: 1.8ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1051_jpg.rf.ce2bc6b32b8b698c1e527ccd8ad89668.jpg: 640x640 164 peoples, 18.0ms\nSpeed: 1.8ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_729_jpg.rf.295dda23576ba21ee14538bcef0227bc.jpg: 640x640 60 peoples, 18.7ms\nSpeed: 1.8ms preprocess, 18.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_37_jpg.rf.ab579e54edbba1e4d13704c06189a17a.jpg: 640x640 43 peoples, 18.6ms\nSpeed: 1.8ms preprocess, 18.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_133_jpg.rf.38ecc260c405ad565fd07170ae65e847.jpg: 640x640 159 peoples, 21.5ms\nSpeed: 1.8ms preprocess, 21.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_465_jpg.rf.71f3f0a6a7f361ecfbb9469a72aef395.jpg: 640x640 110 peoples, 18.4ms\nSpeed: 1.9ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_86_jpg.rf.569468d35587964247dfb95b8ac2e2dd.jpg: 640x640 300 peoples, 18.9ms\nSpeed: 1.7ms preprocess, 18.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1245_jpg.rf.58b19dd9f675f19d3a34e7ad30eaa5be.jpg: 640x640 24 peoples, 18.9ms\nSpeed: 1.8ms preprocess, 18.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1181_jpg.rf.0d46c7dc90e07ceb7672672d1e83d917.jpg: 640x640 300 peoples, 20.3ms\nSpeed: 1.8ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1028_jpg.rf.99caf138b8bd6a105d28fea6b9e21fc1.jpg: 640x640 24 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_153_jpg.rf.7ef65f5c835eed7872fd0b64d182b14f.jpg: 640x640 71 peoples, 19.9ms\nSpeed: 1.9ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_407_jpg.rf.5f5a3d4c778b86be9b8f3d1e67c7dab3.jpg: 640x640 63 peoples, 19.4ms\nSpeed: 1.7ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_465_jpg.rf.77bc88d135089f911479fade4da4b1cf.jpg: 640x640 116 peoples, 19.9ms\nSpeed: 2.0ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_624_jpg.rf.dc9e0d4e783275f55587904de20882cc.jpg: 640x640 160 peoples, 18.7ms\nSpeed: 1.8ms preprocess, 18.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_364_jpg.rf.5d90f7ac6cef52597db4a95d6e78c2f6.jpg: 640x640 20 peoples, 18.6ms\nSpeed: 1.8ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1054_jpg.rf.6c7a2041fa7ddabacb0b402d0c3aa4f9.jpg: 640x640 300 peoples, 20.1ms\nSpeed: 1.8ms preprocess, 20.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1185_jpg.rf.1d48492171a9be4c088f3703365147dc.jpg: 640x640 36 peoples, 17.4ms\nSpeed: 1.9ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_298_jpg.rf.8ade94a00587e99f1c208e26fff7bfc4.jpg: 640x640 27 peoples, 19.1ms\nSpeed: 1.8ms preprocess, 19.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1128_jpg.rf.357218b5d1467eeaf0404e53534134a1.jpg: 640x640 300 peoples, 19.5ms\nSpeed: 1.8ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_534_jpg.rf.f5ab5837f1d641b1508fbd19c55dfdb5.jpg: 640x640 37 peoples, 17.6ms\nSpeed: 1.8ms preprocess, 17.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_177_jpg.rf.0a7414ef9609b6a780c158720b30c00b.jpg: 640x640 112 peoples, 19.9ms\nSpeed: 1.8ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_13_jpg.rf.b6b6c758d0a4054de96286d2ef937ac4.jpg: 640x640 142 peoples, 19.1ms\nSpeed: 1.8ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_142_jpg.rf.21b04dcf23d8206fe9ce10aa0af7c174.jpg: 640x640 154 peoples, 17.7ms\nSpeed: 1.8ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_800_jpg.rf.ba9cc1e345df92d809a8c796ffb97644.jpg: 640x640 41 peoples, 17.3ms\nSpeed: 1.8ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1102_jpg.rf.8a6cef66300df15843bd838ad9acef2c.jpg: 640x640 59 peoples, 18.7ms\nSpeed: 1.8ms preprocess, 18.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1245_jpg.rf.ec049b3137f635b1000d3e725f5d8b7f.jpg: 640x640 28 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_471_jpg.rf.3bd687190e435b23900d5775d4232d6d.jpg: 640x640 262 peoples, 22.0ms\nSpeed: 1.9ms preprocess, 22.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_596_jpg.rf.e1a0f2a20cb210fa80f3427985547f94.jpg: 640x640 116 peoples, 18.1ms\nSpeed: 1.8ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1076_jpg.rf.77f158a5ee2ac5b9d777bd7303be88be.jpg: 640x640 69 peoples, 18.0ms\nSpeed: 1.8ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_539_jpg.rf.d86c9247cf3e244ec11a926ad34fc0da.jpg: 640x640 44 peoples, 18.1ms\nSpeed: 1.9ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1107_jpg.rf.cb58b21a2c8f86fa836ee3370bfa8e58.jpg: 640x640 67 peoples, 20.4ms\nSpeed: 1.9ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_148_jpg.rf.27837be32b4be56bb40423f96575fb1e.jpg: 640x640 32 peoples, 20.4ms\nSpeed: 1.8ms preprocess, 20.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_11_jpg.rf.1abf9fe9e642cb05e00f83bf8c7cc21e.jpg: 640x640 127 peoples, 19.0ms\nSpeed: 1.9ms preprocess, 19.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1031_jpg.rf.d7661e6539c9dbf4a0dacc9a460de0e8.jpg: 640x640 247 peoples, 18.7ms\nSpeed: 1.9ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1019_jpg.rf.cb04a6ec10d9f48b8c0d94374eab6965.jpg: 640x640 35 peoples, 17.6ms\nSpeed: 1.8ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_692_jpg.rf.feb6dc7df5c5c74d0e580688485f3791.jpg: 640x640 49 peoples, 20.7ms\nSpeed: 1.9ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_685_jpg.rf.bc6302993fbc94abc35de205a7b4fdce.jpg: 640x640 33 peoples, 19.8ms\nSpeed: 1.9ms preprocess, 19.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_462_jpg.rf.adb8331250852ee5c658c253a639583c.jpg: 640x640 13 peoples, 19.8ms\nSpeed: 2.0ms preprocess, 19.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1046_jpg.rf.cc3a7c8e50cac033aecbb8cf9a79ed7e.jpg: 640x640 300 peoples, 20.7ms\nSpeed: 1.9ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1261_jpg.rf.63332ba36d2c999b3ecc3148abee9433.jpg: 640x640 300 peoples, 17.9ms\nSpeed: 1.9ms preprocess, 17.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_412_jpg.rf.429b47d3294f55a510c4359ad257fb7f.jpg: 640x640 29 peoples, 17.4ms\nSpeed: 2.0ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1172_jpg.rf.8d5f6cbfb07d2a8292a82437691f47ac.jpg: 640x640 86 peoples, 17.7ms\nSpeed: 1.7ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1034_jpg.rf.7ecb90a14324f49d72b1c7571e7fb684.jpg: 640x640 206 peoples, 20.4ms\nSpeed: 1.8ms preprocess, 20.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_78_jpg.rf.060a1084f0542a5d78a0863620d598f7.jpg: 640x640 41 peoples, 18.3ms\nSpeed: 1.9ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_372_jpg.rf.45ce3d354f6e4e9d6ae4a039e8610477.jpg: 640x640 112 peoples, 18.2ms\nSpeed: 1.8ms preprocess, 18.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1128_jpg.rf.80786604c1599cfbdedaf6b9b54de09a.jpg: 640x640 300 peoples, 18.9ms\nSpeed: 1.8ms preprocess, 18.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_685_jpg.rf.a7eef9edaadee023f2958a07236e4656.jpg: 640x640 33 peoples, 17.8ms\nSpeed: 1.8ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1054_jpg.rf.efc31ee6ad36a28cfac8407c6d634a7f.jpg: 640x640 300 peoples, 19.1ms\nSpeed: 1.9ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_429_jpg.rf.91928db4785218703eed38e2d2d0a789.jpg: 640x640 26 peoples, 17.9ms\nSpeed: 1.9ms preprocess, 17.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1145_jpg.rf.8a28d319c13b741257af1d40aba161fc.jpg: 640x640 48 peoples, 18.5ms\nSpeed: 1.8ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_783_jpg.rf.05c5b755b914134c32d1932adadd6581.jpg: 640x640 96 peoples, 20.4ms\nSpeed: 1.8ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_25_jpeg_jpg.rf.459b8e3ba82a622987c55c5abd1f6fa2.jpg: 640x640 300 peoples, 19.0ms\nSpeed: 1.9ms preprocess, 19.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_172_jpg.rf.43749e15b30a8a5cf8f04b2b08a7db16.jpg: 640x640 206 peoples, 17.5ms\nSpeed: 1.8ms preprocess, 17.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_342_jpg.rf.02f2eec0d48cd7d2e895be0c27586422.jpg: 640x640 32 peoples, 17.2ms\nSpeed: 1.8ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1208_jpg.rf.5aa7d125633ae138b38aaa95f780c971.jpg: 640x640 70 peoples, 20.6ms\nSpeed: 2.0ms preprocess, 20.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_379_jpg.rf.506cb397e5b7a754394a4943b3c140f7.jpg: 640x640 94 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_686_jpg.rf.d5e631151a9d2ce0d0d6ace5b504e5f9.jpg: 640x640 46 peoples, 19.1ms\nSpeed: 1.9ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_53_jpg.rf.3a3173d2cf1ac8777784c07a51413dde.jpg: 640x640 19 peoples, 20.2ms\nSpeed: 1.8ms preprocess, 20.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_506_jpg.rf.d1ff797b7b82172a4affcc6673fdd1c5.jpg: 640x640 62 peoples, 20.1ms\nSpeed: 1.8ms preprocess, 20.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_279_jpg.rf.1f312e846c34b2cf12ad253ea59cd73c.jpg: 640x640 125 peoples, 19.3ms\nSpeed: 1.8ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_10_jpg.rf.4abebdaf7126face87b5dee12399b136.jpg: 640x640 39 peoples, 19.0ms\nSpeed: 1.9ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_344_jpg.rf.2c13e26a3de8f51072fdfb3962d51ed4.jpg: 640x640 106 peoples, 20.4ms\nSpeed: 1.8ms preprocess, 20.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_620_jpg.rf.cc197d53066166a2cf82e4602484b47b.jpg: 640x640 48 peoples, 19.4ms\nSpeed: 1.8ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_411_jpg.rf.da33649b9ba53eca0fa6b78f6b34929e.jpg: 640x640 12 peoples, 19.0ms\nSpeed: 1.8ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_872_jpg.rf.6b9e791d16a25c5d558333708d141cd8.jpg: 640x640 247 peoples, 19.6ms\nSpeed: 1.8ms preprocess, 19.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_675_jpg.rf.3ce1da6d3cbf32d0e69a045a46171b51.jpg: 640x640 11 peoples, 18.0ms\nSpeed: 1.8ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_225_jpg.rf.c6414e1050e7527134790b76123d544e.jpg: 640x640 60 peoples, 17.7ms\nSpeed: 1.8ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1266_jpg.rf.5b7dcec5855756357a5a252ab9038789.jpg: 640x640 88 peoples, 21.1ms\nSpeed: 1.8ms preprocess, 21.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_324_jpg.rf.68c619a82dd8b6f01405d74268a29b9b.jpg: 640x640 161 peoples, 19.8ms\nSpeed: 2.0ms preprocess, 19.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/working/crowd-counting-dataset-1/test/images/img_1017_jpg.rf.54f9fb3d4fb8660eded3bf2ba0b055c7.jpg: 640x640 40 peoples, 17.8ms\nSpeed: 1.8ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from IPython.display import Image, display\ndisplay(Image(filename='runs/detect/predict/your_image.jpg'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:19:40.735528Z","iopub.status.idle":"2025-04-10T11:19:40.735779Z","shell.execute_reply":"2025-04-10T11:19:40.735680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"/kaggle/working/runs/best_Model.pt\")","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom pathlib import Path\nimport pandas as pd\n\n# تحميل الموديل المدرب\nmodel = YOLO(\"/kaggle/input/best-model-pt/best_Model.pt\")  # تأكدي إن اسم الملف نفس اللي عندك\n\n# تحديد مجلد الصور\nimage_dir = Path(\"crowd-counting-dataset-1/test/images\")\n\n# استخراج عدد الأشخاص من كل صورة\nresults_data = []\n\nfor image_file in sorted(image_dir.glob(\"*.jpg\")):\n    results = model(image_file)\n    num_people = sum([1 for r in results[0].boxes.cls if int(r) == 0])  # class 0 = person\n    results_data.append({\n        \"image\": image_file.name,\n        \"person_count\": num_people\n    })\n\n# تحويلها إلى DataFrame\ndf = pd.DataFrame(results_data)\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_congestion_label(count):\n    if count <= 10:\n        return \"خفيف\"\n    elif count <= 30:\n        return \"متوسط\"\n    else:\n        return \"عالي\"\n\ndf[\"congestion_level\"] = df[\"person_count\"].apply(get_congestion_label)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:44:47.724563Z","iopub.execute_input":"2025-04-10T11:44:47.724904Z","iopub.status.idle":"2025-04-10T11:44:47.736064Z","shell.execute_reply.started":"2025-04-10T11:44:47.724880Z","shell.execute_reply":"2025-04-10T11:44:47.735039Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"                                               image  person_count  \\\n0  img_1002_jpg.rf.cd1157993d2488bbdd2d771823fc5c...            86   \n1  img_1017_jpg.rf.54f9fb3d4fb8660eded3bf2ba0b055...            40   \n2  img_1019_jpg.rf.3b463cedbc593b20f89f808a0883b5...            35   \n3  img_1019_jpg.rf.cb04a6ec10d9f48b8c0d94374eab69...            35   \n4  img_1027_jpg.rf.0ede423a7df33f34e9cf76cf365946...            15   \n\n  congestion_level  \n0             عالي  \n1             عالي  \n2             عالي  \n3             عالي  \n4            متوسط  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>person_count</th>\n      <th>congestion_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1002_jpg.rf.cd1157993d2488bbdd2d771823fc5c...</td>\n      <td>86</td>\n      <td>عالي</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_1017_jpg.rf.54f9fb3d4fb8660eded3bf2ba0b055...</td>\n      <td>40</td>\n      <td>عالي</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_1019_jpg.rf.3b463cedbc593b20f89f808a0883b5...</td>\n      <td>35</td>\n      <td>عالي</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_1019_jpg.rf.cb04a6ec10d9f48b8c0d94374eab69...</td>\n      <td>35</td>\n      <td>عالي</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_1027_jpg.rf.0ede423a7df33f34e9cf76cf365946...</td>\n      <td>15</td>\n      <td>متوسط</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"import os\nfrom shutil import copy\n\nos.makedirs(\"cnn_dataset/خفيف\", exist_ok=True)\nos.makedirs(\"cnn_dataset/متوسط\", exist_ok=True)\nos.makedirs(\"cnn_dataset/عالي\", exist_ok=True)\n\nfor _, row in df.iterrows():\n    src = image_dir / row[\"image\"]\n    dst = Path(f\"cnn_dataset/{row['congestion_level']}\") / row[\"image\"]\n    copy(src, dst)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:44:52.779111Z","iopub.execute_input":"2025-04-10T11:44:52.779445Z","iopub.status.idle":"2025-04-10T11:44:52.865929Z","shell.execute_reply.started":"2025-04-10T11:44:52.779416Z","shell.execute_reply":"2025-04-10T11:44:52.865219Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# إعداد البيانات\ndatagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n\ntrain_data = datagen.flow_from_directory(\n    \"cnn_dataset\",\n    target_size=(128, 128),\n    batch_size=16,\n    class_mode=\"categorical\",\n    subset=\"training\"\n)\n\nval_data = datagen.flow_from_directory(\n    \"cnn_dataset\",\n    target_size=(128, 128),\n    batch_size=16,\n    class_mode=\"categorical\",\n    subset=\"validation\"\n)\n\n# نموذج CNN بسيط\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(3, activation='softmax')  # 3 فئات: خفيف، متوسط، عالي\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# تدريب النموذج\nmodel.fit(train_data, epochs=10, validation_data=val_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:45:01.847324Z","iopub.execute_input":"2025-04-10T11:45:01.847654Z","iopub.status.idle":"2025-04-10T11:45:08.138438Z","shell.execute_reply.started":"2025-04-10T11:45:01.847628Z","shell.execute_reply":"2025-04-10T11:45:08.137844Z"}},"outputs":[{"name":"stdout","text":"Found 186 images belonging to 3 classes.\nFound 45 images belonging to 3 classes.\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\nYour `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.6409 - loss: 1.9685 - val_accuracy: 0.7778 - val_loss: 0.8362\nEpoch 2/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7562 - loss: 0.6687 - val_accuracy: 0.7778 - val_loss: 0.5028\nEpoch 3/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7791 - loss: 0.5114 - val_accuracy: 0.7778 - val_loss: 0.5232\nEpoch 4/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9318 - loss: 0.2212 - val_accuracy: 0.7778 - val_loss: 0.5600\nEpoch 5/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9750 - loss: 0.1737 - val_accuracy: 0.7556 - val_loss: 0.7055\nEpoch 6/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9851 - loss: 0.0980 - val_accuracy: 0.7556 - val_loss: 0.7205\nEpoch 7/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.0218 - val_accuracy: 0.7333 - val_loss: 0.8092\nEpoch 8/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.7556 - val_loss: 0.9150\nEpoch 9/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.7556 - val_loss: 1.0731\nEpoch 10/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7556 - val_loss: 1.1156\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c7f4216de70>"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"model.fit(train_data, epochs=10, validation_data=val_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:45:15.489909Z","iopub.execute_input":"2025-04-10T11:45:15.490232Z","iopub.status.idle":"2025-04-10T11:45:18.855219Z","shell.execute_reply.started":"2025-04-10T11:45:15.490205Z","shell.execute_reply":"2025-04-10T11:45:18.854409Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7556 - val_loss: 1.2308\nEpoch 2/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 6.0966e-04 - val_accuracy: 0.7556 - val_loss: 1.1863\nEpoch 3/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 6.2459e-04 - val_accuracy: 0.7556 - val_loss: 1.2618\nEpoch 4/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.7823e-04 - val_accuracy: 0.7556 - val_loss: 1.3133\nEpoch 5/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.0125e-04 - val_accuracy: 0.7556 - val_loss: 1.3037\nEpoch 6/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.2228e-04 - val_accuracy: 0.7556 - val_loss: 1.2856\nEpoch 7/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.9601e-04 - val_accuracy: 0.7556 - val_loss: 1.3535\nEpoch 8/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.6877e-04 - val_accuracy: 0.7556 - val_loss: 1.3150\nEpoch 9/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.4400e-04 - val_accuracy: 0.7556 - val_loss: 1.3472\nEpoch 10/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.3147e-04 - val_accuracy: 0.7556 - val_loss: 1.3813\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c7f422a5390>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\n# نحفظ نتائج التدريب\nhistory = model.fit(train_data, epochs=10, validation_data=val_data)\n\n# نعرض دقة التدريب والتحقق\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('CNN Accuracy Over Epochs')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:45:23.980123Z","iopub.execute_input":"2025-04-10T11:45:23.980459Z","iopub.status.idle":"2025-04-10T11:45:27.350878Z","shell.execute_reply.started":"2025-04-10T11:45:23.980430Z","shell.execute_reply":"2025-04-10T11:45:27.349887Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.1388e-04 - val_accuracy: 0.7556 - val_loss: 1.3847\nEpoch 2/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.2071e-04 - val_accuracy: 0.7556 - val_loss: 1.3404\nEpoch 3/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.5863e-05 - val_accuracy: 0.7556 - val_loss: 1.3922\nEpoch 4/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.2152e-05 - val_accuracy: 0.7556 - val_loss: 1.3880\nEpoch 5/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.0924e-05 - val_accuracy: 0.7556 - val_loss: 1.4282\nEpoch 6/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.4209e-05 - val_accuracy: 0.7556 - val_loss: 1.3971\nEpoch 7/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.0910e-05 - val_accuracy: 0.7556 - val_loss: 1.3902\nEpoch 8/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 6.1505e-05 - val_accuracy: 0.7556 - val_loss: 1.4842\nEpoch 9/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 6.5777e-05 - val_accuracy: 0.7556 - val_loss: 1.4296\nEpoch 10/10\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.0507e-05 - val_accuracy: 0.7556 - val_loss: 1.4446\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('CNN Loss Over Epochs')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:45:31.607780Z","iopub.execute_input":"2025-04-10T11:45:31.608097Z","iopub.status.idle":"2025-04-10T11:45:31.686128Z","shell.execute_reply.started":"2025-04-10T11:45:31.608071Z","shell.execute_reply":"2025-04-10T11:45:31.685451Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"model.save(\"/kaggle/working/cnn_congestion_model.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:43:43.733392Z","iopub.execute_input":"2025-04-10T11:43:43.733713Z","iopub.status.idle":"2025-04-10T11:43:43.842697Z","shell.execute_reply.started":"2025-04-10T11:43:43.733688Z","shell.execute_reply":"2025-04-10T11:43:43.841753Z"}},"outputs":[],"execution_count":46}]}